{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build character map function for encoding URL string\n",
    "\n",
    "import string\n",
    "ascii_letters = string.ascii_letters # 1~52\n",
    "digits = string.digits # 53~62\n",
    "punctuation = string.punctuation # 63~94\n",
    "total_char = ascii_letters + digits + punctuation    \n",
    "\n",
    "UNKNOWN_CHAR = len(total_char) + 1\n",
    "TOTAL_FEATURES = UNKNOWN_CHAR + 1 \n",
    "charmap = {\n",
    "    c: idx+1\n",
    "    for idx, c in enumerate(total_char)\n",
    "}\n",
    "\n",
    "def encodeChar(c):\n",
    "    return charmap.get(c, UNKNOWN_CHAR)\n",
    "\n",
    "encodeChar(\"b\"), encodeChar(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "import pandas\n",
    "import statistics\n",
    "df = pandas.read_csv(\"data.csv\")\n",
    "\n",
    "df[\"len\"] = df.url.apply(lambda s: len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    420464.000000\n",
       "mean         48.342005\n",
       "std          35.021279\n",
       "min           1.000000\n",
       "25%          29.000000\n",
       "50%          41.000000\n",
       "75%          58.000000\n",
       "max        2307.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the length stats\n",
    "df.len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=200 0.60172%\n",
      "x=300 0.12034%\n",
      "x=400 0.07420%\n",
      "x=500 0.06469%\n",
      "x=600 0.04614%\n",
      "x=700 0.02545%\n",
      "x=800 0.01784%\n",
      "x=900 0.00880%\n",
      "x=1000 0.00476%\n"
     ]
    }
   ],
   "source": [
    "# find a Length for large coverage for all sample URL\n",
    "for t in [200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "    print(\"x={} {:.5f}%\".format(t, 100 * sum(df.len.apply(lambda x: x > t)) / len(df.len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336371 84093 420464\n",
      "Loading data...\n",
      "201822 train sequences\n",
      "67275 test sequences\n",
      "67274 val sequences\n"
     ]
    }
   ],
   "source": [
    "# sampling train/test dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df1 = df\n",
    "df1.label = le.fit_transform(df1.label)\n",
    "\n",
    "sub_df, preserved_df = train_test_split(df1, test_size=0.2, random_state=1)\n",
    "print(len(sub_df), len(preserved_df), len(df1))\n",
    "categorical_label = np_utils.to_categorical(sub_df.label)\n",
    "\n",
    "url_train, url_test, y_train, y_test \\\n",
    "    = train_test_split(sub_df.url, categorical_label, test_size=0.2, random_state=1)\n",
    "\n",
    "url_train, url_val, y_train, y_val \\\n",
    "    = train_test_split(url_train, y_train, test_size=0.25, random_state=1) \n",
    "\n",
    "print('Loading data...')\n",
    "print(len(url_train), 'train sequences')\n",
    "print(len(url_test), 'test sequences')\n",
    "print(len(url_val), 'val sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_features = TOTAL_FEATURES\n",
    "maxlen = 400 \n",
    "embedding_size = 128\n",
    "\n",
    "# Training\n",
    "batch_size = 64 \n",
    "epochs = 3\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 2\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Dropout ratio\n",
    "Dropout_ratio = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (201822, 400)\n",
      "x_test shape: (67275, 400)\n",
      "x_val shape: (67274, 400)\n"
     ]
    }
   ],
   "source": [
    "# encode the URL by one-hot encoding and padding feature vector by 'pre'\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "\n",
    "x_train = pad_sequences(url_train.apply(lambda url: numpy.array([encodeChar(c) for c in url])), \n",
    "              maxlen=maxlen, \n",
    "              padding='pre')\n",
    "x_test = pad_sequences(url_test.apply(lambda url: numpy.array([encodeChar(c) for c in url])), \n",
    "              maxlen=maxlen, \n",
    "              padding='pre')\n",
    "\n",
    "x_val = pad_sequences(url_val.apply(lambda url: numpy.array([encodeChar(c) for c in url])), \n",
    "              maxlen=maxlen, \n",
    "              padding='pre')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('x_val shape:', x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"CNN-LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 128)          12288     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 396, 64)           41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 198, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 70)                37800     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 142       \n",
      "=================================================================\n",
      "Total params: 91,254\n",
      "Trainable params: 91,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential(name=\"CNN-LSTM\")\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen, trainable=True))\n",
    "model.add(Conv1D(64,\n",
    "                 5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/3\n",
      "3154/3154 [==============================] - 753s 239ms/step - loss: 0.1442 - accuracy: 0.9468 - val_loss: 0.0896 - val_accuracy: 0.9693\n",
      "Epoch 2/3\n",
      "3154/3154 [==============================] - 737s 234ms/step - loss: 0.0848 - accuracy: 0.9708 - val_loss: 0.0729 - val_accuracy: 0.9752\n",
      "Epoch 3/3\n",
      "3154/3154 [==============================] - 770s 244ms/step - loss: 0.0687 - accuracy: 0.9770 - val_loss: 0.0726 - val_accuracy: 0.9766\n",
      "1052/1052 [==============================] - 72s 69ms/step - loss: 0.0717 - accuracy: 0.9766\n",
      "Test score: 0.07170752435922623\n",
      "Test accuracy: 0.9766480922698975\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=3,validation_data=(x_val, y_val))\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3154/3154 [==============================] - 207s 66ms/step - loss: 0.0594 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05943066254258156, 0.9800071120262146]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 69s 66ms/step - loss: 0.0726 - accuracy: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07256986945867538, 0.9766179919242859]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314/1314 [==============================] - 87s 66ms/step - loss: 0.0750 - accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07504693418741226, 0.9755508899688721]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate preserved_df\n",
    "preserved_x = pad_sequences(preserved_df.url.apply(lambda url: numpy.array([encodeChar(c) for c in url])), \n",
    "              maxlen=maxlen, \n",
    "              padding='pre')\n",
    "\n",
    "preserved_y = np_utils.to_categorical(preserved_df.label)\n",
    "model.evaluate(preserved_x, preserved_y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
